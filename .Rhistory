# plus a normally distributed error of mean 0 and
# standard deviation .3.
y <- x1 + rnorm(length(x1), sd = .3)
# Find the coefficient of x1 in 3 nested linear
# models, the first including only the predictor x1,
# the second x1 and x2, the third x1, x2, and x3.
c(coef(lm(y ~ x1))[2],
coef(lm(y ~ x1 + x2))[2],
coef(lm(y ~ x1 + x2 + x3))[2])
}
# Regressor generation process 1.
rgp1 <- function(){
print("Processing. Please wait.")
# number of samples per simulation
n <- 100
# number of simulations
nosim <- 1000
# set seed for reproducibility
set.seed(4321)
# Point A
x1 <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
# Point B
betas <- sapply(1 : nosim, function(i)makelms(x1, x2, x3))
round(apply(betas, 1, var), 5)
}
# Regressor generation process 2.
rgp2 <- function(){
print("Processing. Please wait.")
# number of samples per simulation
n <- 100
# number of simulations
nosim <- 1000
# set seed for reproducibility
set.seed(4321)
# Point C
x1 <- rnorm(n)
x2 <- x1/sqrt(2) + rnorm(n) /sqrt(2)
x3 <- x1 * 0.95 + rnorm(n) * sqrt(1 - 0.95^2)
# Point D
betas <- sapply(1 : nosim, function(i)makelms(x1, x2, x3))
round(apply(betas, 1, var), 5)
}
rgp(1)
rgp(1)
# Regressor generation process 1.
rgp1 <- function(){
print("Processing. Please wait.")
# number of samples per simulation
n <- 100
# number of simulations
nosim <- 1000
# set seed for reproducibility
set.seed(4321)
# Point A
x1 <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
# Point B
betas <- sapply(1 : nosim, function(i)makelms(x1, x2, x3))
round(apply(betas, 1, var), 5)
}
rgp(1)
rpg(1)
rgp1()
rgp2()
head(swiss)
mdl <- lm(Fertility ~ Agriculture + Examination + Education + Catholic + Infant.Mortality, data=swiss)
vif(mdl)
mdl2 <- lm(Fertility ~ Agriculture + Education + Catholic + Infant.Mortality, data=swiss)
vif(mdl2)
asdas
library(swirl)
swirl()
x1c <- simbias()
apply(x1c, 1, mean)
fit1 <- (Fertility ~ Agriculture, data=swiss)
fit1 <- lm(Fertility ~ Agriculture, data=swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, data=swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- (deviance(fit1)-deviance(fit3))/2
n/d
pf(n/d,2,43,lower.tail=FALSE)
shapiro.test(fit3$residuals)
anove(fit1, fit3, fit5, fit6)
anova(fit1, fit3, fit5, fit6)
ravenData
mdl <- glm(ravenWinNum ~ ravenScore, family="binomial", data=ravenData)
lodds <- predict(mdl, data.frame(ravenScore=c(0,3,6)))
exp(lodds)/(1=exp(lodds))
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(.95, 1)
var(rpois(1000,50))
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, family="Poisson", data=hits)
mdl <- glm(visits ~ date, family="poisson", data=hits)
summary(mdl)
summary(mdl)
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
mdl2 <- glm(visits ~ date, family="poisson", data=hits, offset=log(visits+1))
mdl2 <- glm(simplystats ~ date, family="poisson", data=hits, offset=log(visits+1))
qpois(.95, mdl2$fitted.values[704])
x <- c(1, 2, 3, 4, 5)
y <- c(1, 1, 1, 1, 1)
df <- data.frame(x, y)
df
library(tidyr)
?spread
spread(df, x, y)
fact <- c("1_2", "2_3", "3_4", "4_5")
fact
model.matrix(fact)
?model.matrix
model.matrix(as.factor(fact))
df <- as.data.frame(fact)
df
model.matrix(as.factor(df$fact))
y <- c(1,1,1,1)
f <- data.frame(y, fact)
f
model.matrx(y ~ fact)
model.matrix(y ~ fact)
model.matrix(y ~ fact - 1)
weeknr <- c("1_2", "2_3", "3_4", "4_5")
y <- c(1, 1, 1, 1, 1, 1)
weeknr <- c("1_2", "2_3", "3_4", "4_5")
y <- c(1, 1, 1, 1, 1, 1)
df <- data.frame(y, weeknr)
model.matrix(y ~ weeknr - 1)
weeknr <- c("1_2", "2_3", "3_4", "4_5")
y <- c(1, 1, 1, 1)
df <- data.frame(y, weeknr)
model.matrix(y ~ weeknr - 1)
weeknr <- c("1_2", "2_3", "3_4", "4_5", "5_6", "6_7")
y <- c(1, 1, 1, 1, 1, 1)
df <- data.frame(y, weeknr)
model.matrix(y ~ weeknr - 1)
?vif
library(nsdm)
library(ndsm)
library(car)
?vif
vif_func<-function(in_frame,thresh=10,trace=T,...){
require(fmsb)
if(class(in_frame) != 'data.frame') in_frame<-data.frame(in_frame)
#get initial vif value for all comparisons of variables
vif_init<-NULL
var_names <- names(in_frame)
for(val in var_names){
regressors <- var_names[-which(var_names == val)]
form <- paste(regressors, collapse = '+')
form_in <- formula(paste(val, '~', form))
vif_init<-rbind(vif_init, c(val, VIF(lm(form_in, data = in_frame, ...))))
}
vif_max<-max(as.numeric(vif_init[,2]), na.rm = TRUE)
if(vif_max < thresh){
if(trace==T){ #print output of each iteration
prmatrix(vif_init,collab=c('var','vif'),rowlab=rep('',nrow(vif_init)),quote=F)
cat('\n')
cat(paste('All variables have VIF < ', thresh,', max VIF ',round(vif_max,2), sep=''),'\n\n')
}
return(var_names)
}
else{
in_dat<-in_frame
#backwards selection of explanatory variables, stops when all VIF values are below 'thresh'
while(vif_max >= thresh){
vif_vals<-NULL
var_names <- names(in_dat)
for(val in var_names){
regressors <- var_names[-which(var_names == val)]
form <- paste(regressors, collapse = '+')
form_in <- formula(paste(val, '~', form))
vif_add<-VIF(lm(form_in, data = in_dat, ...))
vif_vals<-rbind(vif_vals,c(val,vif_add))
}
max_row<-which(vif_vals[,2] == max(as.numeric(vif_vals[,2]), na.rm = TRUE))[1]
vif_max<-as.numeric(vif_vals[max_row,2])
if(vif_max<thresh) break
if(trace==T){ #print output of each iteration
prmatrix(vif_vals,collab=c('var','vif'),rowlab=rep('',nrow(vif_vals)),quote=F)
cat('\n')
cat('removed: ',vif_vals[max_row,1],vif_max,'\n\n')
flush.console()
}
in_dat<-in_dat[,!names(in_dat) %in% vif_vals[max_row,1]]
}
return(names(in_dat))
}
}
?fmsb
install.packages("fmsb")
df <- mtcars
head(df)
exvars <- df[,-1]
vif_func(exvars)
library(usdm)
?vif
vifstep(exvars)
df <- mtcars
str(df)
df$cyl <- as.factor(df$cyl)
str(df)
?apply
df <- mtcars
str(df)
df[, c(2, 8, 9, 10, 11)] <- apply(df[, c(2, 8, 9, 10, 11)], as.factor)
df[, c(2, 8, 9, 10, 11)] <- sapply(df[, c(2, 8, 9, 10, 11)], as.factor)
str(df)
df[, c(2, 8, 9, 10, 11)] <- apply(df[, c(2, 8, 9, 10, 11)], 2, as.factor)
strs(df)
str(df)
df <- mtcars
df[, c(2, 8, 9, 10, 11)] <- apply(df[, c(2, 8, 9, 10, 11)], 2, as.factor)
df
str(df)
df <- mtcars
df[, c(2, 8, 9, 10, 11)] <- apply(apply(df[, c(2, 8, 9, 10, 11)], 2, as.character), 2, as.factor)
str(df)
df <- mtcars
df[, c(2, 8, 9, 10, 11)] <- lapply(df[, c(2, 8, 9, 10, 11)], 2, as.factor)
df <- mtcars
df[, c(2, 8, 9, 10, 11)] <- lapply(df[, c(2, 8, 9, 10, 11)], as.factor)
str(df)
df <- mtcars
str(df)
head(df)
df[, c(2, 8, 9, 10, 11)] <- lapply(df[, c(2, 8, 9, 10, 11)], as.factor)
str(df)
pairs(df)
?mtcars
levels(df$am) <- c("Automatic", "Manual")
strs(df)
str(df)
<-
df <- mtcars
df$am[, df$am==0] <- "Automatic"
df$am[df$am==0] <- "Automatic"
df$am[df$am==1] <- "Manual"
df[, c(2, 8, 9, 10, 11)] <- lapply(df[, c(2, 8, 9, 10, 11)], as.factor)
str(df)
head(df$am)
as.numeric(df$am)
df <- mtcars
df[, c(2, 8, 10, 11)] <- lapply(df[, c(2, 8, 10, 11)], as.factor)
df$am <- factor(df$am, labels = c("Automatic", "Manual"))
str(df)
vifstep(df[,-1])
vifstep(as.matrix(df[,-1]))
exvars <- data.frame(mtcars)[,-1]
exvars
vifstep(exvars)
?ggplot
library(ggplot2)
ggplot?
?ggplot
g <- ggplot(df, aes(y=mpg, x=am))
g + geom_boxplot
# Boxplot mpg ~ am
g <- ggplot(df, aes(y=mpg, x=am))
g + geom_boxplot()
?geom_boxplot
g <- ggplot(df, aes(y=mpg, x=am))
g + geom_boxplot(aes(fill=am))
?mtcars
g <- ggplot(df, aes(y=mpg, x=am))
g +
geom_boxplot(aes(fill=am)) +
labs(x="Transmission type",
y="Miles per gallon",
title="Boxplot of miles per gallon per transmission type")
g <- ggplot(df, aes(y=mpg, x=am))
g +
geom_boxplot(aes(fill=am)) +
labs(x="Transmission type",
y="Miles per gallon",
title="Boxplot of miles per gallon per transmission type") +
guides(fill=FALSE)
vifstep(mtcars[,-1])
?step
step(nullmdl, fullmdl, direction="forward")
nullmdl <- lm(mpg ~ am, data=df)
fullmdl <- lm(mpg ~ am + hp + drat + wt + qsec + vs + gear + carb)
## Forward
step(nullmdl, fullmdl, direction="forward")
nullmdl <- lm(mpg ~ am, data=df)
fullmdl <- lm(mpg ~ am + hp + drat + wt + qsec + vs + gear + carb, data=df)
step(nullmdl, fullmdl, direction="forward")
formula(fullmdl)
step(nullmdl, formula(fullmdl), direction="forward")
step(nullmdl, formula(fullmdl), direction="forward", trace=0)
fmdl <- step(fullmdl, formula(nullmdl), direction="backward", trace=0)
fmdl <- step(nullmdl, scope=list(lower=nullmdl, upper=fullmdl), direction="forward", trace=0)
fmdl
bmdl <- step(fullmdl, scope=list(lower=nullmdl, upper=fullmdl), direction="backward", trace=0)
bmdl
?anova
anova(fmdl, bmdl)
anova(bmdl, nullmdl)
summary(bmdl)
summary(fmdl)
plot(bmdl)
par(mfrow=c(2,2))
plot(bmdl)
plot(fmdl)
anova(bmdl, fmdl)
anova(nullmdl, bmdl)
summary(bmdl)
# Check and load required packages
if ("data.table" %in% rownames(installed.packages())) {
library(data.table)
} else {
install.packages("data.table")
library(data.table)
}
# Check and load required packages
if ("leaflet" %in% rownames(installed.packages())) {
library(leaflet)
} else {
install.packages("leaflet")
library(data.table)
}
?package
paste(package)
?paste
package <- function(package) {
if (package %in% rownames(installed.packages())) {
library(package)
} else {
install.packages(package)
library(package)
}
}
package(ggplot2)
package("ggplot2")
paste(package, sep="", collapse="")
paste(package, sep="")
print(package)
print(ggplot2)
package <- function(package) {
if (package %in% rownames(installed.packages())) {
library(print(package))
} else {
install.packages(print(package))
library(print(package))
}
}
package(test)
package <- function(package) {
name <- as.character(package)
if (name %in% rownames(installed.packages())) {
library(name)
} else {
install.packages(name)
library(name)
}
}
package(test)
package("test")
package <- function(package) {
name <- as.character(package)
if (name %in% rownames(installed.packages())) {
library(print(name))
} else {
install.packages(print(name))
library(print(name))
}
}
package(test)
package("test")
package <- function(package) {
name <- as.character(package)
if (name %in% rownames(installed.packages())) {
library(name)
} else {
install.packages(name)
library(name)
}
}
package("dplyr")
name
name <- "dplyr"
name
library(name)
print(name)
library(print(name))
library(print(name)[1])
if ("test" %in% rownames(installed.packages())) {
library(usdm)
} else {
stop("Install the ggplot2 package first before running this script")
}
if ("dplyr" %in% rownames(installed.packages())) {
library(dplyr)
} else {
stop("Install the ggplot2 package first before running this script")
}
?mtcars
install.packages("caret")
library(caret)
traindata <- mtcars[,-1]
response <- mtcars[,1]
ctrl <- trainControl(method="cv", number="10")
lmFit <- train(x=traindata, y=response, method="lm", preProc=c("center", "scale"), trControl=ctrl)
ctrl <- trainControl(method="cv", number=10)
lmFit <- train(x=traindata, y=response, method="lm", preProc=c("center", "scale"), trControl=ctrl)
summary(lmFit)
x
traindata
bmdl
lmFit <- train(x=traindata[, c(5,6,8)], y=response, method="lm", preProc=c("center", "scale"), trControl=ctrl)
summary(lmFit)
summary(bmdl)
uitstroom
Uitstroom
# Library
library(ggplot2)
library(scales)
library(dplyr)
library(magrittr)
library(caret)
library(MASS)
library(nnet)
library(randomForest)
library(parallel)
library(doParallel)
# Working directory
setwd("D:/R Directories/Coursera/Practical Machine Learning")
# Load test- and train datasets
test <- read.csv("pml-testing.csv")
train <- read.csv("pml-training.csv")
# Remove response and unnecessary variables
response <- train[,160]
train <- train[,-c(1:7, 160)]
test <- test[,-c(1:7, 160)]
# Missing values
dfm <- train %>%
apply(2, as.numeric) %>%
apply(2, function(x) sum(is.na(x))) %>%
{data.frame(Names=names(.), MV=.)}
table(dfm$MV)
dfm <- dfm %>%
filter(MV >0) %>%
.$Names
train <- train[,!(names(train) %in% dfm)]
test <- test[,!(names(test) %in% dfm)]
rm(dfm)
# Near zero variance
nearZeroVar(train, saveMetrics=T)
# Enable parallelized computing
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
# Training parameters
ctrl <- trainControl(method="cv", number=10, allowParallel=T)
preP <- preProcess(train, method=c("center", "scale"))
train_stand <- predict(preP, train)
# Multinomial logistic regression
set.seed(2017)
logfit <- train(x=train_stand, y=response, method="multinom",
trControl=ctrl, trace=FALSE)
# Linear discriminant analysis
set.seed(2017)
ldafit <- train(x=train_stand, y=response, method="lda",
trControl=ctrl)
# Random forest
set.seed(2017)
rffit <- train(x=train_stand, y=response, method="rf",
trControl=ctrl)
# Support vector machine with linear kernel
set.seed(2017)
lsvmfit <- train(x=train_stand, y=response, method="svmLinear", tunelength=14,
trControl=ctrl)
# XGBOOST
set.seed(2017)
xgbfit <- train(x=train_stand, y=response, method="xgbLinear",
trControl=ctrl, nthread=1)
# Stop parallel
stopCluster(cluster)
#
allResamples <- resamples(list("Multinom log" = logfit,
"LDA" = ldafit,
"RandomForest" = rffit
"Linear SVM" = lsvmfit,
"XGBoost" = xgbfit)
)
allResamples <- resamples(list("Multinom log" = logfit,
"LDA" = ldafit,
"RandomForest" = rffit,
"Linear SVM" = lsvmfit,
"XGBoost" = xgbfit)
)
allResamples$models
allResamples$metrics
allResamples$values
allResamples$methods
summary(allResamples)
parallelplot(allResamples)
?parallelplot
confusionMatrix(xgbfit)
confusionMatrix(rffit)
